## HashMap 的长度为什么是2的幂次方

添加数据时，需要通过hash值和数组长度确定key在数组中存放位置的下表，传统方法是`hash%length`，取模远不如位运算高效，HashMap源码中使用与运算：`hash&(length-1)`，**hash%length==hash&(length-1)的前提是 length 是2的 n 次方**；

## 什么是 HashMap 的加载因子？加载因子为什么是 0.75？

判断什么时候进行扩容的，假如加载因子是 0.5，HashMap 的初始化容量是 16，那么当 HashMap 中有 16*0.5=8 个元素时，HashMap 就会进行扩容。

这其实是出于容量和性能之间平衡的结果：

* 当加载因子设置比较大的时候，扩容的门槛就被提高了，扩容发生的频率比较低，占用的空间会比较小，但此时发生Hash冲突的几率就会提升，因此需要更复杂的数据结构来存储元素，这样对元素的操作时间就会增加，运行效率也会因此降低；
* 而当加载因子值比较小的时候，扩容的门槛会比较低，因此会占用更多的空间，多次扩容也会影响性能。
* HashMap的容量有一个固定的要求就是一定是2的幂次方。所以，如果负载因子是3/4的话，那么和capacity的乘积结果就可以是一个整数。

所以综合了以上情况就取了一个 0.5 到 1.0 的平均数 0.75 作为加载因子。

## put 方法流程

简述：通过hash函数获得key的hash值，通过(n-1)&hash找到当前元素的存放位置，如果该位置上已存在元素，通过拉链法解决冲突，过长的链会转化为红黑树。

详细过程：

```plaintext
1. 首先计算key的hash值，然后调用putVal方法
2. 是否首次添加元素，首次则创建一个长度为16的Node数组。
3. 不是首次，则根据hash值和数组长度找到得到应该插入的位置：(n-1)&hash
    若该位置上为空，则直接插入；
    若不为空，先判断头结点的key与插入key相同，是则直接覆盖，否则判断节点类型是链表还是红黑树：
	若为红黑树则将新节点放入树中；
	若为链表，则与链表上的每个结点依次比较，先比较hash值，hash值相同再调用equals方法，若为true，说明key相等，则用新value替换旧value，比较到链尾也没有发现重复key，则在链表尾部添加该键值对。添加完成还需要判断是否需要树化。
4. 添加完成后判断是否需要扩容。
```

## HashMap 的扩容机制

扩容时机：当`size`大于`threshold`的时候，并不一定会触发扩容机制，只要有一个新建的节点出现哈希冲突，则立刻`resize`。

- size记录的是map中包含的Entry的数量
- 而threshold记录的是需要resize的阈值 且 `threshold = loadFactor * capacity`
- capacity 其实就是桶的长度

步骤：

* 数组，阈值都扩大一倍
* 如果旧数组不为空，开始遍历旧数组
* 遍历到的数组上只有一个元素，就直接迁移
* 如果是红黑树就使用 split 方法
* 如果是链表就把链表拆成两个，按照高位运算的结果放到新数组中并且保留顺序

#### JDK 1.8 在扩容方面对 HashMap 做了哪些优化？

1.7创建一个容量的新数组，重新计算每个元素在数组中的位置并且进行迁移。

1.8中在扩容HashMap的时候，不需要像1.7中去重新计算元素的hash，只需要看看原来的hash值新增的哪个二进制数是1还是0就好了，如果是0的话表示索引没有变，是1的话表示索引变成“oldCap+原索引”，这样即省去了重新计算hash值的时间，并且扩容后链表元素位置不会倒置。

## HashMap 1.7和1.8版本区别

* **数据结构：**1.7：数组+链表，1.8：数组+链表+红黑树
* **新节点插入方式：**1.7：头插法 ，1.8：直接在尾部插入
* **扰动运算次数：**1.7：运算多，1.8：运算少
* **插入和扩容的判断：**1.7：先扩容后插入，1.8：先插入后扩容
  *   * 为什么？1.8增加了判断是否为红黑树节点，先扩容的话不知道到底扩链表节点还是红黑树。

## HashMap为什么不直接使用hashCode()处理后的哈希值直接作为table的下标？

`hashCode()`方法返回的是int整数类型，其范围为-(2 ^ 31)~(2 ^ 31 - 1)，  而HashMap的容量范围是在16（初始化默认值）~2 ^ 30，  HashMap通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过`hashCode()`计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置；

**怎么解决呢？**

1.HashMap自己实现了自己的`hash()`方法，通过两次扰动使得它自己的哈希值高低位自行进行异或运算，降低哈希碰撞概率也使得数据分布更平均；

2.保证数组长度为2的幂次方的时候，使用`hash()`运算之后的值与运算（&）（数组长度 - 1）来获取数组下标的方式进行存储。

**那为什么是两次扰动呢？**

这样就是加大哈希值低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性&均匀性，最终减少Hash冲突，两次就够了，已经达到了高位低位同时参与运算的目的；

## HashMap1.7为什么不安全？⭐

HashMap在rehash的时候，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他put操作，如果hash值相同，把值插入同一个链表，会因为头插法的特性造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。

#### 高并发下HashMap1.7的环是如何产生的

若当前线程一此时获得ertry节点，但是被线程中断无法继续执行，此时线程二进入transfer函数，并把函数顺利执行，此时新表中的某个位置有了节点，之后线程一获得执行权继续执行，在tranfer方法中会把next指向自己造成闭环，然后在get时会出现死循环。

## 为什么HashMap中String、Integer这样的包装类适合作为Key？⭐

String、Integer等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率

1. 都是final类型，即不可变性，保证key的不可更改性，不会存在获取hash值不同的情况
2. 内部已重写了`equals()`、`hashCode()`等方法，遵守了HashMap内部的规范，不容易出现Hash值计算错误的情况。

**如果我想要让自己的Object作为K应该怎么办呢？**

重写`hashCode()`和`equals()`方法 。 **重写`hashCode()`是因为需要计算存储数据的存储位置**， **重写`equals()`方法** **目的是为了保证key在哈希表中的唯一性**；

面试题**：谈谈你对HashMap中put/get方法的认识？如果了解再谈HashMap 的扩容机制？默认大小是多少？什么是负载因子(或填充比)？

- 负载因子的大小决定了HashMap的数据密度。
- 负载因子越大密度越大，发生碰撞的几率越高，数组中的链表越容易长，查询或插入时的比较次数增多，性能会下降。
- 负载因子越小，越容易触发扩容，数据密度也越小，性能会更高。但是会浪费一定的内容空间。而且经常扩容也会影响性能，建议初始化预设大一点的空间。
- 按照其他语言的参考及研究经验，会考虑将负载因子设置为0.7~0.75，此时平均检索长度接近于常数。

HashMap与Hashtable区别：

|                | HashMap              | Hashtable              |
| -------------- | -------------------- | ---------------------- |
| 底层数据结构   | 数组+链表+红黑树     | 数组+链表              |
| 初始容量及扩容 | 16，2倍              | 11，2n+1               |
| 线程安全       | 否                   | 是，基于synchronized   |
| 效率           | 较高                 | 较低                   |
| 支持null       | key和value都可为null | 不允许key和value为null |